{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PEDESRAIN DETECTION**"
      ],
      "metadata": {
        "id": "BlDRv_6_Ujnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NebhHXPGiyOG",
        "outputId": "fdfa50de-c954-434d-d3a1-81026ab5bf58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir INRIA_DATASET"
      ],
      "metadata": {
        "id": "k7QkchoUi5_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r drive/MyDrive/DATASET/* ./INRIA_DATASET/"
      ],
      "metadata": {
        "id": "SyLB8fuijaRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "8p7_qi4ymGaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi # T4 GPU"
      ],
      "metadata": {
        "id": "HE0NB1tMcLaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e4745b9-45ce-4d0f-d4ee-ad1fbab0c356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf INRIA_DATASET/"
      ],
      "metadata": {
        "id": "fci7HQTrvj5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Extraction**"
      ],
      "metadata": {
        "id": "7gNacgM4aD5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extract HOG features**"
      ],
      "metadata": {
        "id": "p-cxrO2TUp6O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "WIN_SIZE = (64, 128)  # Standard window size for human detection\n",
        "BLOCK_SIZE = (16, 16)  # Size of blocks for feature analysis\n",
        "BLOCK_STRIDE = (8, 8)  # How much blocks move across the image (over)\n",
        "CELL_SIZE = (8, 8)     # Size of cells that make up blocks\n",
        "HISTOGRAM_BINS = 9     # Number of gradient directions to track\n",
        "\n",
        "\n",
        "def extract_hog_features(img):\n",
        "    \"\"\"\n",
        "    Extract HOG (Histogram of Oriented Gradients) features from an images\n",
        "    \"\"\"\n",
        "    # Create HOG descriptor with our configuration\n",
        "    hog = cv2.HOGDescriptor(\n",
        "        WIN_SIZE,\n",
        "        BLOCK_SIZE,\n",
        "        BLOCK_STRIDE,\n",
        "        CELL_SIZE,\n",
        "        HISTOGRAM_BINS\n",
        "    )\n",
        "\n",
        "    # Calculate features and flatten to 1D array for the SVM\n",
        "    return hog.compute(img).flatten()"
      ],
      "metadata": {
        "id": "8Bqrb8Y9Xj2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Extract LBP features**"
      ],
      "metadata": {
        "id": "WB2q9hTSZ6u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.feature import local_binary_pattern\n",
        "\n",
        "def extract_lbp_features(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    lbp = local_binary_pattern(gray, 8, 1, method='uniform')\n",
        "    hist, _ = np.histogram(lbp, bins=59, range=(0, 58))\n",
        "    hist = hist.astype(np.float32)\n",
        "    hist /= (hist.sum() + 1e-6)\n",
        "    return hist.flatten()"
      ],
      "metadata": {
        "id": "AmY3OuBLbYfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualization HOG**"
      ],
      "metadata": {
        "id": "gt9Mw9MkfM5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import hog\n",
        "from skimage import exposure\n",
        "\n",
        "\n",
        "path = '/content/lady.jpg'\n",
        "image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# Compute HOG features\n",
        "features, hog_image = hog(image, pixels_per_cell=(\n",
        "    16, 16), cells_per_block=(2, 2), visualize=True)\n",
        "\n",
        "# hadi ghir to improve hog visualization\n",
        "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
        "\n",
        "# Display\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image, cmap=plt.cm.gray)\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
        "plt.title('HOG Visualization')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6bBct4ZfWF4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualization LBP**"
      ],
      "metadata": {
        "id": "GQvkPiPxfeJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.feature import local_binary_pattern\n",
        "\n",
        "\n",
        "path = '/content/lady.jpg'\n",
        "image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# LBP params\n",
        "radius = 1\n",
        "n_points = 8 * radius\n",
        "\n",
        "\n",
        "lbp_image = local_binary_pattern(image, n_points, radius, method='uniform')\n",
        "\n",
        "# Display\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(image, cmap=plt.cm.gray)\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(lbp_image, cmap=plt.cm.gray)\n",
        "plt.title('LBP Image')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "MOuZd-MDflJd",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "fa022108-3600-4e65-8d35-8b75f0d66d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The parameter `image` must be a 2-dimensional array",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-ef2857b875e0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mlbp_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_binary_pattern\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skimage/feature/texture.py\u001b[0m in \u001b[0;36mlocal_binary_pattern\u001b[0;34m(image, P, R, method)\u001b[0m\n\u001b[1;32m    373\u001b[0m            \u001b[0;34m:\u001b[0m\u001b[0mDOI\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;36m10.1109\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mTPAMI\u001b[0m\u001b[0;36m.2006\u001b[0m\u001b[0;36m.244\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     \"\"\"\n\u001b[0;32m--> 375\u001b[0;31m     \u001b[0mcheck_nD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     methods = {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/skimage/_shared/utils.py\u001b[0m in \u001b[0;36mcheck_nD\u001b[0;34m(array, ndim, arg_name)\u001b[0m\n\u001b[1;32m    711\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_empty_array\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0mmsg_incorrect_dim\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marg_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-or-'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: The parameter `image` must be a 2-dimensional array"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Data**"
      ],
      "metadata": {
        "id": "g3lX-noyVQvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_dataset(pos_folder, neg_folder, feature_extractor):\n",
        "    \"\"\"\n",
        "    Load positive (human) and negative (non-human) images,\n",
        "    extract features, and create labels for training\n",
        "    \"\"\"\n",
        "    features, labels = [], []\n",
        "\n",
        "    for filename in os.listdir(pos_folder):\n",
        "        img_path = os.path.join(pos_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, WIN_SIZE)\n",
        "        if img is not None:\n",
        "            features.append(feature_extractor(img))\n",
        "            labels.append(1)  # Positive samples labeled as 1\n",
        "\n",
        "    for filename in os.listdir(neg_folder):\n",
        "        img_path = os.path.join(neg_folder, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, WIN_SIZE)\n",
        "        if img is not None:\n",
        "            features.append(feature_extractor(img))\n",
        "            labels.append(-1)  # Negative samples labeled as -1\n",
        "\n",
        "    return np.array(features, dtype=np.float32), np.array(labels)"
      ],
      "metadata": {
        "id": "z9F2Zm9ZVWqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Model Using SVM**\n",
        "\n"
      ],
      "metadata": {
        "id": "Rd1FQfMuVaYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_svm(feature_extractor, model_name):\n",
        "    \"\"\"\n",
        "    loads data and trains the SVM classifier\n",
        "    \"\"\"\n",
        "\n",
        "    train_pos = \"INRIA_DATASET/train/pos\"\n",
        "    train_neg = \"INRIA_DATASET/train/neg\"\n",
        "\n",
        "    #  training data\n",
        "    print(\"Loading training images...\")\n",
        "    X_train, y_train = load_dataset(train_pos, train_neg, feature_extractor)\n",
        "\n",
        "    # Set up SVM classifier\n",
        "    print(\"Setting up SVM classifier...\")\n",
        "    svm = cv2.ml.SVM_create()\n",
        "\n",
        "    svm.setType(cv2.ml.SVM_C_SVC)\n",
        "    if model_name == \"hog\":\n",
        "      svm.setKernel(cv2.ml.SVM_LINEAR) # Linear kernel works well with HOG for this prj\n",
        "      # svm.setC(0.01)\n",
        "      # svm.setGamma(0.5)\n",
        "    if model_name == \"lbp\":\n",
        "      svm.setKernel(cv2.ml.SVM_CHI2) # CHI2 kernel works well with LBP for this prj\n",
        "      # svm.setC(2.5)\n",
        "      # svm.setGamma(0.1)\n",
        "\n",
        "    # Train the model\n",
        "    print(\"Training model...\")\n",
        "    svm.train(X_train, cv2.ml.ROW_SAMPLE, y_train)  # ROW_SAMPLE each row corresponds to a vector\n",
        "\n",
        "    # Save\n",
        "    svm.save(f\"{model_name}_svm.xml\")\n",
        "    print(f\"{model_name} model trained and saved as {model_name}_svm.xml\\n\")\n",
        "\n",
        "\n",
        "train_model_svm(extract_hog_features,\"hog\")\n",
        "train_model_svm(extract_lbp_features,\"lbp\")"
      ],
      "metadata": {
        "id": "u0BOk_LqXzqM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "169f4b84-a100-43d9-be8d-f440b8da98ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training images...\n",
            "Setting up SVM classifier...\n",
            "Training model...\n",
            "hog model trained and saved as hog_svm.xml\n",
            "\n",
            "Loading training images...\n",
            "Setting up SVM classifier...\n",
            "Training model...\n",
            "lbp model trained and saved as lbp_svm.xml\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train Model using AdaBoost**"
      ],
      "metadata": {
        "id": "UNzjwdgHSM22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_adaboost(feature_extractor, model_name):\n",
        "    # Load dataset\n",
        "    train_pos = \"INRIA_DATASET/train/pos\"\n",
        "    train_neg = \"INRIA_DATASET/train/neg\"\n",
        "\n",
        "    X_train, y_train = load_dataset(train_pos, train_neg, feature_extractor)\n",
        "\n",
        "    # Create AdaBoost classifier\n",
        "    print(\"Setting up AdaBoost...\")\n",
        "    boost = cv2.ml.Boost_create()\n",
        "\n",
        "    boost.setBoostType(cv2.ml.BOOST_REAL)\n",
        "    boost.setWeakCount(10)\n",
        "    boost.setWeightTrimRate(0.95)\n",
        "    boost.setMaxDepth(1)\n",
        "    boost.setUseSurrogates(False)\n",
        "    boost.setWeightTrimRate(0.99)\n",
        "\n",
        "    # Create training data structure\n",
        "    train_data = cv2.ml.TrainData_create(\n",
        "        X_train,\n",
        "        cv2.ml.ROW_SAMPLE,\n",
        "        y_train\n",
        "    )\n",
        "\n",
        "    # Train the model (params already set via Boost_create)\n",
        "    print(\"Training AdaBoost...\")\n",
        "    boost.train(train_data)\n",
        "\n",
        "    # Save\n",
        "    boost.save(f\"{model_name}_boost.xml\")\n",
        "    print(f\"{model_name} AdaBoost model saved as {model_name}_boost.xml\\n\")\n",
        "\n",
        "train_model_adaboost(extract_hog_features, \"hog\")\n",
        "train_model_adaboost(extract_lbp_features, \"lbp\")"
      ],
      "metadata": {
        "id": "goIRU007SXel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dc8f94a-2474-4702-a0c1-524922c49ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up AdaBoost...\n",
            "Training AdaBoost...\n",
            "hog AdaBoost model saved as hog_boost.xml\n",
            "\n",
            "Setting up AdaBoost...\n",
            "Training AdaBoost...\n",
            "lbp AdaBoost model saved as lbp_boost.xml\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluate Classifier**"
      ],
      "metadata": {
        "id": "JbQXZWKzYIar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(test_pos, test_neg, model_path, feature_extractor):\n",
        "    if \"svm\" in model_path.lower():\n",
        "        model = cv2.ml.SVM_load(model_path)\n",
        "    else:\n",
        "        model = cv2.ml.Boost_load(model_path)\n",
        "\n",
        "    tp, fp, tn, fn = 0, 0, 0, 0\n",
        "\n",
        "    # Test positive images\n",
        "    for filename in os.listdir(test_pos):\n",
        "        img_path = os.path.join(test_pos, filename)\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.resize(img, WIN_SIZE)\n",
        "        feature = feature_extractor(img)\n",
        "        _, pred = model.predict(np.array([feature]))\n",
        "        tp += 1 if pred[0][0] == 1 else 0\n",
        "        fn += 1 if pred[0][0] != 1 else 0\n",
        "\n",
        "    # Test negative images\n",
        "    for filename in os.listdir(test_neg):\n",
        "        img = cv2.imread(os.path.join(test_neg, filename))\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, WIN_SIZE)\n",
        "            feat = feature_extractor(img)\n",
        "            _, pred = model.predict(np.array([feat]))\n",
        "            tn += 1 if pred[0][0] == -1 else 0\n",
        "            fp += 1 if pred[0][0] != -1 else 0\n",
        "\n",
        "    return tp, fp, tn, fn\n"
      ],
      "metadata": {
        "id": "EfkykprrYMRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Test SVM**"
      ],
      "metadata": {
        "id": "51GUaVWKY5r3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(test_pos, test_neg,hog_model , lbp_model):\n",
        "    # Load HOG model\n",
        "    svm = cv2.ml.SVM_load(hog_model)\n",
        "\n",
        "    # Evaluate HOG model\n",
        "    tp, fp, tn, fn = evaluate_model(test_pos, test_neg,hog_model, extract_hog_features)\n",
        "\n",
        "    # Print HOG results\n",
        "    print(f\"HOG+SVM Model Performance:\")\n",
        "    print(f\"True Positives: {tp}\")\n",
        "    print(f\"False Positives: {fp}\")\n",
        "    print(f\"True Negatives: {tn}\")\n",
        "    print(f\"False Negatives: {fn}\")\n",
        "    print(f\"Accuracy: {(tp + tn) / (tp + tn + fp + fn):.2%}\")\n",
        "    print(f\"Precision: {tp/(tp+fp) if (tp+fp)!=0 else 0:.2%}\")\n",
        "    # print(f\"Recall: {tp/(tp+fn) if (tp+fn)!=0 else 0:.2%}\")\n",
        "    # print(f\"F1: {2*(tp/(tp+fp))*(tp/(tp+fn))/((tp/(tp+fp))+(tp/(tp+fn))) if (tp+fp)*(tp+fn)!=0 else 0:.2%}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Load LBP model\n",
        "    svm = cv2.ml.SVM_load(\"lbp_svm.xml\")\n",
        "\n",
        "    # Evaluate LBP model\n",
        "    tp, fp, tn, fn =  evaluate_model(test_pos, test_neg,lbp_model, extract_lbp_features)\n",
        "\n",
        "    # Print LBP results\n",
        "    print(f\"LBP+SVM Model Performance:\")\n",
        "    print(f\"True Positives: {tp}\")\n",
        "    print(f\"False Positives: {fp}\")\n",
        "    print(f\"True Negatives: {tn}\")\n",
        "    print(f\"False Negatives: {fn}\")\n",
        "    print(f\"Accuracy: {(tp + tn) / (tp + tn + fp + fn):.2%}\")\n",
        "    print(f\"Precision: {tp/(tp+fp) if (tp+fp)!=0 else 0:.2%}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "\n",
        "test_pos = \"INRIA_DATASET/test/pos\"\n",
        "test_neg = \"INRIA_DATASET/test/neg\"\n",
        "test(test_pos, test_neg, \"hog_svm.xml\", \"lbp_svm.xml\")"
      ],
      "metadata": {
        "id": "6pK3B42UY8tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93bc2b92-49fb-4e5b-dcc6-6b14c19028f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOG+SVM Model Performance:\n",
            "True Positives: 1186\n",
            "False Positives: 6\n",
            "True Negatives: 435\n",
            "False Negatives: 13\n",
            "Accuracy: 98.84%\n",
            "Precision: 99.50%\n",
            "----------------------------------------\n",
            "LBP+SVM Model Performance:\n",
            "True Positives: 1191\n",
            "False Positives: 29\n",
            "True Negatives: 412\n",
            "False Negatives: 8\n",
            "Accuracy: 97.74%\n",
            "Precision: 97.62%\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Final Test AdaBoost**"
      ],
      "metadata": {
        "id": "842xyIf5dK8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_adaboost(test_pos, test_neg, hog_boost_model, lbp_boost_model):\n",
        "    # Evaluate HOG+AdaBoost\n",
        "    tp, fp, tn, fn = evaluate_model(test_pos, test_neg,hog_boost_model, extract_hog_features)\n",
        "    print(\"HOG+AdaBoost Performance:\")\n",
        "    print(f\"True Positives: {tp}\")\n",
        "    print(f\"False Positives: {fp}\")\n",
        "    print(f\"True Negatives: {tn}\")\n",
        "    print(f\"False Negatives: {fn}\")\n",
        "    print(f\"Accuracy: {(tp + tn) / (tp + tn + fp + fn):.2%}\")\n",
        "    print(f\"Precision: {tp/(tp+fp) if (tp+fp)!=0 else 0:.2%}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    # Evaluate LBP+AdaBoost\n",
        "    tp, fp, tn, fn =  evaluate_model(test_pos, test_neg,lbp_boost_model, extract_lbp_features)\n",
        "    print(\"LBP+AdaBoost Performance:\")\n",
        "    print(f\"True Positives: {tp}\")\n",
        "    print(f\"False Positives: {fp}\")\n",
        "    print(f\"True Negatives: {tn}\")\n",
        "    print(f\"False Negatives: {fn}\")\n",
        "    print(f\"Accuracy: {(tp + tn) / (tp + tn + fp + fn):.2%}\")\n",
        "    print(f\"Precision: {tp/(tp+fp) if (tp+fp)!=0 else 0:.2%}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Usage\n",
        "test_pos = \"INRIA_DATASET/test/pos\"\n",
        "test_neg = \"INRIA_DATASET/test/neg\"\n",
        "test_adaboost(test_pos, test_neg, \"hog_boost.xml\", \"lbp_boost.xml\")"
      ],
      "metadata": {
        "id": "n7xQgf1UdHe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de440403-35c0-4c73-b435-8bfcd29d7fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HOG+AdaBoost Performance:\n",
            "True Positives: 1128\n",
            "False Positives: 53\n",
            "True Negatives: 388\n",
            "False Negatives: 71\n",
            "Accuracy: 92.44%\n",
            "Precision: 95.51%\n",
            "----------------------------------------\n",
            "LBP+AdaBoost Performance:\n",
            "True Positives: 1189\n",
            "False Positives: 28\n",
            "True Negatives: 413\n",
            "False Negatives: 10\n",
            "Accuracy: 97.68%\n",
            "Precision: 97.70%\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Large Image**"
      ],
      "metadata": {
        "id": "o4j8laxcbQhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window_detection(image_path, model_path, feature_extractor, window_size=(64,128), step_size=32):\n",
        "\n",
        "    if \"svm\" in model_path.lower():\n",
        "        model = cv2.ml.SVM_load(model_path)\n",
        "    else:\n",
        "        model = cv2.ml.Boost_load(model_path)\n",
        "    image = cv2.imread(image_path)\n",
        "    # image dimensions\n",
        "    image_height, image_width = image.shape[:2]\n",
        "    bounding_boxes = []\n",
        "\n",
        "    # Iterate over the image using a sliding window\n",
        "    for y in range(0, image_height - window_size[1] + 1, step_size):\n",
        "        for x in range(0, image_width - window_size[0] + 1, step_size):\n",
        "            # Extract the current window from the image\n",
        "            window = image[y:y + window_size[1], x:x + window_size[0]]\n",
        "            window = cv2.resize(window, WIN_SIZE)\n",
        "\n",
        "            # Extract features from the window\n",
        "            features = feature_extractor(window)\n",
        "\n",
        "            # Make a prediction using the trained model\n",
        "            _, prediction = model.predict(np.array([features]))\n",
        "\n",
        "            if prediction[0][0] == 1:  # Assuming 1 indicates a pedestrian\n",
        "                bounding_boxes.append((x, y, window_size[0], window_size[1]))\n",
        "\n",
        "    return bounding_boxes\n",
        "\n",
        "# Example\n",
        "image_path = '/content/figure1.jpg'\n",
        "model_path = 'lbp_svm.xml'  # Path to your trained model\n",
        "bounding_boxes = sliding_window_detection(image_path, model_path, extract_lbp_features)\n",
        "\n",
        "# Draw bounding boxes on the image (optional)\n",
        "image = cv2.imread(image_path)\n",
        "for (x, y, w, h) in bounding_boxes:\n",
        "    cv2.putText(image, 'Pedestrian', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "\n",
        "# Display the image with bounding boxes (optional)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert BGR (OpenCV) to RGB (Matplotlib)\n",
        "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Display using Matplotlib\n",
        "plt.imshow(image_rgb)\n",
        "plt.title(\"Pedestrian Detection\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-g2BxdmXbTN2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "1b265da6-9993-4bf9-ecc6-a9c06094ebe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.11.0) /io/opencv/modules/ml/src/svm.cpp:2010: error: (-215:Assertion failed) samples.cols == var_count && samples.type() == CV_32F in function 'predict'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-05003195b79a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/figure1.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lbp_svm.xml'\u001b[0m  \u001b[0;31m# Path to your trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mbounding_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliding_window_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_lbp_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Draw bounding boxes on the image (optional)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-05003195b79a>\u001b[0m in \u001b[0;36msliding_window_detection\u001b[0;34m(image_path, model_path, feature_extractor, window_size, step_size)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;31m# Make a prediction using the trained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Assuming 1 indicates a pedestrian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/ml/src/svm.cpp:2010: error: (-215:Assertion failed) samples.cols == var_count && samples.type() == CV_32F in function 'predict'\n"
          ]
        }
      ]
    }
  ]
}